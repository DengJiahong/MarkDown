# 作业 2 报告

### 201300069 邓嘉宏 1739413207@qq.com

## 任务一

MiniMax搜索算法基于当前的状态, 搜索选择最有利于自己而不利于对手的行动.

在MiniMaxDecider.java中, 类成员maximize决定自己是要选择最大值还是最小值(当maximize=1时, 为max; 当maximize=0时, 为min.); depth 为限制的搜索深度; computedStates 计算局面的值(匹配到哈希值).

`public Action decide(State state)`函数为算法的具体过程, 搜索下一个该走的动作.

`public float miniMaxRecursor(State state, int depth, boolean maximize)`函数递归计算当前局面的评估分.

对类中函数的具体理解如下:

```Java

public class MiniMaxDecider implements Decider {
	
	// 决定自己是要选择最大值还是最小值
	private boolean maximize;
	// 搜索的深度
	private int depth;
	// 计算局面的值(匹配到哈希值)
	private Map<State, Float> computedStates;
	// Used to generate a graph of the search space for each turn in SVG format
	private static final boolean DEBUG = true;
	
	//初始化以上成员变量
	public MiniMaxDecider(boolean maximize, int depth) {
		this.maximize = maximize;
		this.depth = depth;
		computedStates = new HashMap<State, Float>();
	}
	
	
	@SuppressWarnings({ "unchecked", "rawtypes" })
    //该函数选择下一个要走的动作
	public Action decide(State state) {
		// 根据选择最大值还是最小值将value赋值为正无穷或负无穷
		float value = maximize ? Float.NEGATIVE_INFINITY : Float.POSITIVE_INFINITY;
        //bestActions为可选的动作
		List<Action> bestActions = new ArrayList<Action>();
		// 以下通过迭代计算各结点的值
		int flag = maximize ? 1 : -1;
        //遍历所有可走的点
		for (Action action : state.getActions()) {
			try {
				//下该点后的局面
				State newState = action.applyTo(state);
                //下该点后当前局面的评估分
				float newValue = this.miniMaxRecursor(newState, 1, !this.maximize);
				//若评估分比之前的候选点高则替代之前的候选点
				if (flag * newValue > flag * value) {
					value = newValue;
					bestActions.clear();
				}
				if (flag * newValue >= flag * value) bestActions.add(action);
			} catch (InvalidActionException e) {
				throw new RuntimeException("Invalid action!");
			}
		}
		//若有多个评估分相同的候选点,则随机选择其一
		Collections.shuffle(bestActions);
		return bestActions.get(0);
	}
	
	@SuppressWarnings({ "rawtypes", "unchecked" })
    //该函数递归计算传入状态的评估分
	public float miniMaxRecursor(State state, int depth, boolean maximize) {
		// 已计算过该状态得分,直接返回
		if (computedStates.containsKey(state)) 
                    return computedStates.get(state);
		// 计算到终结点,返回评估分
		if (state.getStatus() != Status.Ongoing)
                    return finalize(state, state.heuristic());
		// 到达最大递归深度,返回评估分
		if (depth == this.depth)
                    return state.heuristic();
                
		//递归计算
		float value = maximize ? Float.NEGATIVE_INFINITY : Float.POSITIVE_INFINITY;
		int flag = maximize ? 1 : -1;
		List<Action> test = state.getActions();
		for (Action action : test) {
			//遍历每个动作,并计算新状态的值
			try {
				State childState = action.applyTo(state);
				float newValue = this.miniMaxRecursor(childState, depth + 1, !maximize);
				//记录最好的评估值
                                if (flag * newValue > flag * value) 
                                    value = newValue;
			} catch (InvalidActionException e) {
				throw new RuntimeException("Invalid action!");
			}
		}
		return finalize(state, value);
	}
	
	//非哈希值计算评估分
	private float finalize(State state, float value) {
		//直接返回
		return value;
	}
	
}
```



## 任务二

在`public Action decide()`中计算并输出引入剪枝后带来的时间变化;

在`public float miniMaxRecursor()`中具体实现剪枝;



```Java
	//统计时间
	int count = 0;
	double totaltime_minimax = 0;
	double totaltime_ab = 0;

	@SuppressWarnings({ "unchecked", "rawtypes" })
	public Action decide(State state) {
		double start = System.currentTimeMillis();
		double time_minimax = 0;
		double time_ab = 0;
		// Choose randomly between equally good options
		float value = maximize ? Float.NEGATIVE_INFINITY : Float.POSITIVE_INFINITY;
		List<Action> bestActions = new ArrayList<Action>();
		// Iterate!
		int flag = maximize ? 1 : -1;
		for (Action action : state.getActions()) {
			try {
				// Algorithm!
				State newState = action.applyTo(state);
				//float newValue = this.miniMaxRecursor(newState, 1, !this.maximize);
				float newValue = this.miniMaxRecursor(newState, 1, !this.maximize, Float.NEGATIVE_INFINITY, Float.POSITIVE_INFINITY, false);
				time_minimax = System.currentTimeMillis() - start;
				float ab_newValue = this.miniMaxRecursor(newState, 1, !this.maximize, Float.NEGATIVE_INFINITY, Float.POSITIVE_INFINITY, true);
				time_ab = System.currentTimeMillis() - start - time_minimax;
				//assert (newValue == ab_newValue);
				// Better candidates?
				System.out.println("Minimax Time:");
				System.out.println(time_minimax);
				System.out.println("AlphaBeta Time:");
				System.out.println(time_ab);
				totaltime_minimax += time_minimax;
				totaltime_ab += time_ab;
				count ++;
				if (count % 10 == 0)
				{
					System.out.println("Average Minimax Time:");
					System.out.println(totaltime_minimax / count);
					System.out.println("Average AlphaBeta Time:");
					System.out.println(totaltime_ab / count);
				}
				if (flag * newValue > flag * value) {
					value = newValue;
					bestActions.clear();
				}
				// Add it to the list of candidates?
				if (flag * newValue >= flag * value) bestActions.add(action);
			} catch (InvalidActionException e) {
				throw new RuntimeException("Invalid action!");
			}
		}
		// If there are more than one best actions, pick one of the best randomly
		Collections.shuffle(bestActions);
		return bestActions.get(0);
	}

	/**
	 * The true implementation of the MiniMax algorithm!
	 * Thoroughly commented for your convenience.
	 * @param state    The State we are currently parsing.
	 * @param alpha    The alpha bound for alpha-beta pruning.
	 * @param beta     The beta bound for alpha-beta pruning.
	 * @param depth    The current depth we are at.
	 * @param maximize Are we maximizing? If not, we are minimizing.
	 * @return The best point count we can get on this branch of the state space to the specified depth.
	 */
	@SuppressWarnings({ "rawtypes", "unchecked" })
	public float miniMaxRecursor(State state, int depth, boolean maximize, float alpha, float beta, boolean abflag) {
		// Has this state already been computed?
		if (computedStates.containsKey(state))
			// Return the stored result
			return computedStates.get(state);
		// Is this state done?
		if (state.getStatus() != Status.Ongoing)
			// Store and return
			return finalize(state, state.heuristic());
		// Have we reached the end of the line?
		if (depth == this.depth)
			//Return the heuristic value
			return state.heuristic();

		// If not, recurse further. Identify the best actions to take.
		float value = maximize ? Float.NEGATIVE_INFINITY : Float.POSITIVE_INFINITY;
		int flag = maximize ? 1 : -1;
		float upperbound = maximize ? beta : alpha;
		float lowerbound = maximize? alpha : beta;
		List<Action> test = state.getActions();
		for (Action action : test) {
			// Check it. Is it better? If so, keep it.
			try {
				State childState = action.applyTo(state);
				//float newValue = this.miniMaxRecursor(childState, depth + 1, !maximize);
				float newValue = this.miniMaxRecursor(childState, depth + 1, !maximize, alpha, beta, abflag);
				//Record the best value
				if (flag * newValue > flag * value)
					value = newValue;
				if (abflag) {
					if (flag * value >= flag * upperbound) {
						return finalize(state, value);
					}
					if (flag * value > flag * lowerbound) {
						lowerbound = value;
					}
				}
			} catch (InvalidActionException e) {
				//Should not go here
				throw new RuntimeException("Invalid action!");
			}
		}
		// Store so we don't have to compute it again.
		return finalize(state, value);
	}
```



**性能变化: **

观察前两步的时间:

当搜索深度为2: Minimax Time:1.0     ;      AlphaBeta Time:1.0

当搜索深度为3: Minimax Time:3.0     ;      AlphaBeta Time:2.0

当搜索深度为5: Minimax Time:11.0     ;      AlphaBeta Time:6.0

随着搜索深度的增大, 剪枝带来的性能提升越来越明显.



## 任务3

理解`heuristic()`函数:

该函数的返回值为: 对双方不同方面的差异根据重要性赋予不同的权重再求和.

```java
public float heuristic() {
   //获取当前局面
   Status s = this.getStatus();
   int winconstant = 0;
   //若获胜等5000分,失败-5000分
   switch (s) {
   case PlayerOneWon:
      winconstant = 5000;
      break;
   case PlayerTwoWon:
      winconstant = -5000;
      break;
   default:
      winconstant = 0;
      break;
   }
   /*
   双方在棋盘上棋子数的差值,权重为1;
   当前局面上双方可落子位置数的差值,权重为8;
   双方占领角点数的差值,权重为300;
   双方可被翻转的棋子数的差值,权重为1;
   最后再加上能否获胜的得分.
   */
   return this.pieceDifferential() +
      8 * this.moveDifferential() +
     300 * this.cornerDifferential() +
      1 * this.stabilityDifferential() + 
      winconstant;
}
```



因为在边缘的棋子更稳定, 更不容易被翻转, 所以可以赋予更大的权重, 所以可以在`heuristic()`中增加这部分棋子(根据函数`edgeDifferential()`求出) 的得分.

具体改进:

```Java
public float heuristic() {
   //获取当前局面
   Status s = this.getStatus();
   int winconstant = 0;
   //若获胜等5000分,失败-5000分
   switch (s) {
   case PlayerOneWon:
      winconstant = 5000;
      break;
   case PlayerTwoWon:
      winconstant = -5000;
      break;
   default:
      winconstant = 0;
      break;
   }
   /*
   双方在棋盘上棋子数的差值,权重为1;
   当前局面上双方可落子位置数的差值,权重为8;
   双方占领角点数的差值,权重为300;
   双方可被翻转的棋子数的差值,权重为1;
   最后再加上能否获胜的得分.
   */
   return this.pieceDifferential() +
      8 * this.moveDifferential() +
     300 * this.cornerDifferential() +
      1 * this.stabilityDifferential() + 
      winconstant+
      //当前局面双方在边缘位置的棋子数的差值,权重为50;
      50 * this.edgeDifferential();
}
```





## 任务4

MTDDecider算法的流程由`private int MTDF()`函数展示:

```Java
	//首先猜测一个评估分firstGuess, 限定深度depth
	//不断限制评估分的界限
	private int MTDF(State root, int firstGuess, int depth)
			throws OutOfTimeException {
        //初始化
		int g = firstGuess;
		int beta;
		int upperbound = WIN;//正无穷
		int lowerbound = LOSE;//负无穷

		int flag = maximizer ? 1 : -1;
		//beta等于g或者lowerbound+1
		while (lowerbound < upperbound) {
			if (g == lowerbound) {
				beta = g + 1;
			} else {
				beta = g;
			}
		/*
		AlphaBetaWithMemory()使用Alpha-Beta剪枝和转换表方法,
		返回minimax值的界限
		*/
			g = -AlphaBetaWithMemory(root, beta - 1, beta, depth, -flag);
            //更新lowerbound或者upperbound,
            //缩小评估分的界限
			if (g < beta) {
				upperbound = g;
			} else {
				lowerbound = g;
			}
		}
		return g;
	}
```



**MTDDecider与MiniMaxDecider:**

**异:**

MTDDecider使用了alpha-beta剪枝和置换表方法, 而MiniMaxDecider未使用.

**同:**

两者都是根据MiniMax评估分和搜索深度来做出决策.





